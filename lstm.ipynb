{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YmXubP4VamqE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmXubP4VamqE",
    "outputId": "60b5dc72-9930-4ff9-c152-6bd4c3d8012e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b334c0c",
   "metadata": {
    "id": "1b334c0c"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "#from konlpy.tag import Mecab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc184e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bGWaS-LVTQpG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1738237261280,
     "user": {
      "displayName": "김재민",
      "userId": "14133616262020169823"
     },
     "user_tz": -540
    },
    "id": "bGWaS-LVTQpG",
    "outputId": "483da3c8-c3c6-4532-e3ee-1982eeb1abae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Mecab-ko-for-Google-Colab\n"
     ]
    }
   ],
   "source": [
    "cd Mecab-ko-for-Google-Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash install_mecab-ko_on_colab_light_220429.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IlFfbTudD4zq",
   "metadata": {
    "id": "IlFfbTudD4zq"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/ADV/RAW(일반 + 피싱) + TRAIN + TEST/raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XJPaCNEMEDuy",
   "metadata": {
    "id": "XJPaCNEMEDuy"
   },
   "outputs": [],
   "source": [
    "aug = pd.read_csv('/content/drive/MyDrive/adv/data/aug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leXoD_Tey6P8",
   "metadata": {
    "id": "leXoD_Tey6P8"
   },
   "outputs": [],
   "source": [
    "total_data = pd.concat([data,aug],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd7021",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ddd7021",
    "outputId": "9cfe8750-f882-4138-dc97-039810192dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(total_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N25KSl34EMSK",
   "metadata": {
    "id": "N25KSl34EMSK"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(total_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed1c7ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "fed1c7ab",
    "outputId": "9d911188-2d78-4ab6-8755-68a14daa5263"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e9f889490>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d3f90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d5d3f90",
    "outputId": "7f934b9a-66b2-4fd0-8b58-7f31f19d6097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  count\n",
      "0      0  44283\n",
      "1      1   2188\n"
     ]
    }
   ],
   "source": [
    "print(train_data.groupby('label').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845617c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "845617c0",
    "outputId": "7ad760c3-7486-4c89-eeef-4ca796a515b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46420 entries, 28587 to 56422\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   txt     46420 non-null  object\n",
      " 1   label   46420 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna()\n",
    "train_df = train_data.copy()\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce55b8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ce55b8c",
    "outputId": "77fee26e-b2cd-42c8-d3f9-852c3842696a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-fbce5ea24231>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['txt'] = train_df['txt'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt      0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df['txt'] = train_df['txt'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_df['txt'].replace('', np.nan, inplace=True)\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff117f9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff117f9f",
    "outputId": "601f1238-5ab7-4d06-ec6e-951427deeabf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11618 entries, 30943 to 34901\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   txt     11598 non-null  object\n",
      " 1   label   11618 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 272.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df = test_data.copy()\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343e363",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5343e363",
    "outputId": "c42ad047-8744-4726-f754-9e695265f35b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 테스트용 샘플의 개수:  11596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-96e2153da749>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_df['txt'] = test_df['txt'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
     ]
    }
   ],
   "source": [
    "test_df.drop_duplicates(subset='txt', inplace=True)\n",
    "test_df['txt'] = test_df['txt'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_df['txt'].replace('', np.nan, inplace=True)\n",
    "test_df = test_df.dropna(how='any')\n",
    "print('전처리 후 테스트용 샘플의 개수: ', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vQzHXrxNpEKF",
   "metadata": {
    "id": "vQzHXrxNpEKF"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c643601d",
   "metadata": {
    "id": "c643601d"
   },
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340ec80",
   "metadata": {
    "id": "0340ec80"
   },
   "outputs": [],
   "source": [
    "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Um6aBln5Sva",
   "metadata": {
    "id": "6Um6aBln5Sva"
   },
   "outputs": [],
   "source": [
    "train_df=train_df.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1a3db",
   "metadata": {
    "id": "a3a1a3db"
   },
   "outputs": [],
   "source": [
    "train_df['tokenized'] = train_df['txt'].apply(mecab.morphs)\n",
    "train_df['tokenized'] = train_df['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836fece",
   "metadata": {
    "id": "4836fece"
   },
   "outputs": [],
   "source": [
    "test_df['tokenized'] = test_df['txt'].apply(mecab.morphs)\n",
    "test_df['tokenized'] = test_df['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea5b07",
   "metadata": {
    "id": "12ea5b07"
   },
   "outputs": [],
   "source": [
    "normal_words = np.hstack(train_df[train_df.label == 0]['tokenized'].values)\n",
    "pishing_words = np.hstack(train_df[train_df.label == 1]['tokenized'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66728f2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66728f2e",
    "outputId": "ff1d9e4f-05d4-4399-f40d-0afbd99637a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ㅇㅇㅇ', 108837), ('님', 107588), ('고객', 107529), ('요', 101917), ('확인', 101687), ('로', 80247), ('입니다', 78472), ('ㅇㅇㅇㅇ', 70959), ('감사합니다', 62705), ('해', 59008), ('으로', 55251), ('ㅇㅇ', 54207), ('아', 54055), ('말씀', 52432), ('카드', 52024), ('상품', 50840), ('주문', 46425), ('에서', 44119), ('알겠습니다', 42475), ('드리겠습니다', 40497), ('수', 36141), ('번호', 34577), ('됩니다', 33536), ('결제', 32140), ('하고', 31839), ('부탁', 31690), ('만', 31411), ('할', 31250), ('드릴', 30353), ('있습니다', 30231)]\n"
     ]
    }
   ],
   "source": [
    "normal_word_count = Counter(normal_words)\n",
    "print(normal_word_count.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049a7aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8049a7aa",
    "outputId": "fa1b7f68-3a84-42e6-be61-7de6284751b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('그', 16905), ('예', 14352), ('지금', 13799), ('본인', 12697), ('으로', 10609), ('요', 9997), ('저희', 9835), ('제', 9763), ('이제', 8983), ('로', 8032), ('님', 8029), ('에서', 7873), ('거', 7593), ('어', 7237), ('고객', 6886), ('통장', 6474), ('수', 6023), ('하고', 5245), ('서', 5055), ('확인', 5010), ('뭐', 4963), ('계좌', 4930), ('적', 4833), ('만', 4820), ('부분', 4816), ('일', 4779), ('좀', 4686), ('은행', 4519), ('안', 4431), ('말씀', 4380)]\n"
     ]
    }
   ],
   "source": [
    "pishing_word_count = Counter(pishing_words)\n",
    "print(pishing_word_count.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42a543",
   "metadata": {
    "id": "8b42a543"
   },
   "outputs": [],
   "source": [
    "X_train = train_df['tokenized'].values\n",
    "y_train = train_df['label'].apply(lambda x: 0 if x == 0 else 1)\n",
    "X_test = test_df['tokenized'].values\n",
    "y_test = test_df['label'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd2a33",
   "metadata": {
    "id": "d5dd2a33"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945eb3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d945eb3a",
    "outputId": "6c66c403-345c-44cd-aaf6-74cb88f223ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 75835\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 26103\n",
      "단어 집합에서 희귀 단어의 비율: 34.42078196083603\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 0.3070851218593714\n"
     ]
    }
   ],
   "source": [
    "threshold = 2\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaeecc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eaeecc3",
    "outputId": "6bd26ebc-21ee-400b-f4a0-b739a2f062e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기:  49734\n"
     ]
    }
   ],
   "source": [
    "vocab_size = total_cnt - rare_cnt + 2\n",
    "print('단어 집합의 크기: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802bb25",
   "metadata": {
    "id": "1802bb25"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size, oov_token='OOV')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072292a",
   "metadata": {
    "id": "8072292a"
   },
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ad105",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db5ad105",
    "outputId": "0978927c-a4b5-4c5d-9771-ef638cfa6bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 190 이하인 샘플의 비율: 67.16932356742782\n"
     ]
    }
   ],
   "source": [
    "max_len = 190\n",
    "below_threshold_len(max_len, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a06444",
   "metadata": {
    "id": "45a06444"
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da372a12",
   "metadata": {
    "id": "da372a12"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn)\n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn)\n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e225c68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e225c68",
    "outputId": "8dc5ee03-6aae-4eb4-b395-647b61ba07ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1161/1161 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9906 - precision: 0.6796 - recall: 0.7146 - f1score: 0.6881\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99580, saving model to best_model4.h5\n",
      "1161/1161 [==============================] - 278s 236ms/step - loss: 0.0091 - accuracy: 0.9906 - precision: 0.6796 - recall: 0.7146 - f1score: 0.6881 - val_loss: 0.0168 - val_accuracy: 0.9958 - val_precision: 0.7553 - val_recall: 0.7796 - val_f1score: 0.7619\n",
      "Epoch 2/10\n",
      "1161/1161 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9979 - precision: 0.7707 - recall: 0.7846 - f1score: 0.7751\n",
      "Epoch 2: val_accuracy improved from 0.99580 to 0.99882, saving model to best_model4.h5\n",
      "1161/1161 [==============================] - 277s 239ms/step - loss: 0.0013 - accuracy: 0.9979 - precision: 0.7707 - recall: 0.7846 - f1score: 0.7751 - val_loss: 0.0052 - val_accuracy: 0.9988 - val_precision: 0.7878 - val_recall: 0.7955 - val_f1score: 0.7901\n",
      "Epoch 3/10\n",
      "1161/1161 [==============================] - ETA: 0s - loss: 4.1818e-04 - accuracy: 0.9991 - precision: 0.7776 - recall: 0.7851 - f1score: 0.7802\n",
      "Epoch 3: val_accuracy improved from 0.99882 to 0.99892, saving model to best_model4.h5\n",
      "1161/1161 [==============================] - 268s 231ms/step - loss: 4.1818e-04 - accuracy: 0.9991 - precision: 0.7776 - recall: 0.7851 - f1score: 0.7802 - val_loss: 0.0046 - val_accuracy: 0.9989 - val_precision: 0.7907 - val_recall: 0.7955 - val_f1score: 0.7919\n",
      "Epoch 4/10\n",
      "1161/1161 [==============================] - ETA: 0s - loss: 2.0574e-05 - accuracy: 0.9999 - precision: 0.7842 - recall: 0.7847 - f1score: 0.7844\n",
      "Epoch 4: val_accuracy improved from 0.99892 to 0.99925, saving model to best_model4.h5\n",
      "1161/1161 [==============================] - 269s 232ms/step - loss: 2.0574e-05 - accuracy: 0.9999 - precision: 0.7842 - recall: 0.7847 - f1score: 0.7844 - val_loss: 0.0041 - val_accuracy: 0.9992 - val_precision: 0.7935 - val_recall: 0.7955 - val_f1score: 0.7938\n",
      "Epoch 5/10\n",
      "1161/1161 [==============================] - ETA: 0s - loss: 6.9697e-06 - accuracy: 1.0000 - precision: 0.7627 - recall: 0.7631 - f1score: 0.7628\n",
      "Epoch 5: val_accuracy did not improve from 0.99925\n",
      "1161/1161 [==============================] - 271s 233ms/step - loss: 6.9697e-06 - accuracy: 1.0000 - precision: 0.7627 - recall: 0.7631 - f1score: 0.7628 - val_loss: 0.0040 - val_accuracy: 0.9992 - val_precision: 0.7935 - val_recall: 0.7955 - val_f1score: 0.7938\n",
      "Epoch 6/10\n",
      "1161/1161 [==============================] - ETA: 0s - loss: 3.4303e-06 - accuracy: 1.0000 - precision: 0.7674 - recall: 0.7674 - f1score: 0.7674\n",
      "Epoch 6: val_accuracy improved from 0.99925 to 0.99935, saving model to best_model4.h5\n",
      "1161/1161 [==============================] - 273s 235ms/step - loss: 3.4303e-06 - accuracy: 1.0000 - precision: 0.7674 - recall: 0.7674 - f1score: 0.7674 - val_loss: 0.0040 - val_accuracy: 0.9994 - val_precision: 0.7935 - val_recall: 0.7955 - val_f1score: 0.7938\n",
      "Epoch 7/10\n",
      "1161/1161 [==============================] - ETA: 0s - loss: 1.7849e-06 - accuracy: 1.0000 - precision: 0.7666 - recall: 0.7666 - f1score: 0.7666\n",
      "Epoch 7: val_accuracy did not improve from 0.99935\n",
      "1161/1161 [==============================] - 280s 241ms/step - loss: 1.7849e-06 - accuracy: 1.0000 - precision: 0.7666 - recall: 0.7666 - f1score: 0.7666 - val_loss: 0.0038 - val_accuracy: 0.9994 - val_precision: 0.7935 - val_recall: 0.7955 - val_f1score: 0.7938\n",
      "Epoch 8/10\n",
      "1161/1161 [==============================] - ETA: 0s - loss: 1.1385e-06 - accuracy: 1.0000 - precision: 0.7640 - recall: 0.7640 - f1score: 0.7640\n",
      "Epoch 8: val_accuracy did not improve from 0.99935\n",
      "1161/1161 [==============================] - 277s 238ms/step - loss: 1.1385e-06 - accuracy: 1.0000 - precision: 0.7640 - recall: 0.7640 - f1score: 0.7640 - val_loss: 0.0040 - val_accuracy: 0.9991 - val_precision: 0.7918 - val_recall: 0.7955 - val_f1score: 0.7926\n",
      "Epoch 9/10\n",
      "1161/1161 [==============================] - ETA: 0s - loss: 5.9990e-07 - accuracy: 1.0000 - precision: 0.7786 - recall: 0.7786 - f1score: 0.7786\n",
      "Epoch 9: val_accuracy did not improve from 0.99935\n",
      "1161/1161 [==============================] - 273s 235ms/step - loss: 5.9990e-07 - accuracy: 1.0000 - precision: 0.7786 - recall: 0.7786 - f1score: 0.7786 - val_loss: 0.0042 - val_accuracy: 0.9991 - val_precision: 0.7918 - val_recall: 0.7955 - val_f1score: 0.7926\n",
      "Epoch 10/10\n",
      "1161/1161 [==============================] - ETA: 0s - loss: 3.3739e-07 - accuracy: 1.0000 - precision: 0.7735 - recall: 0.7735 - f1score: 0.7735\n",
      "Epoch 10: val_accuracy did not improve from 0.99935\n",
      "1161/1161 [==============================] - 271s 234ms/step - loss: 3.3739e-07 - accuracy: 1.0000 - precision: 0.7735 - recall: 0.7735 - f1score: 0.7735 - val_loss: 0.0041 - val_accuracy: 0.9991 - val_precision: 0.7918 - val_recall: 0.7955 - val_f1score: 0.7926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/content/drive/MyDrive/adv/lstm_model.pkl']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import joblib\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model4.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "class_weight = {0: 0.1,\n",
    "                1: 0.9}\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', precision, recall, f1score])\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[es, mc], batch_size=32,class_weight=class_weight, validation_split=0.2)\n",
    "\n",
    "joblib.dump(model, '/content/drive/MyDrive/adv/lstm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bab468",
   "metadata": {
    "id": "59bab468"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "dependencies = {\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1score': f1score\n",
    "}\n",
    "\n",
    "loaded_model = load_model('best_model4.h5', custom_objects=dependencies)\n",
    "# print('\\n 테스트 정확도: %.4f' %(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9457236",
   "metadata": {
    "id": "c9457236",
    "outputId": "0ec4ab50-5619-4839-b068-30aa0bce049c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1483 - accuracy: 0.9626 - precision: 0.9723 - recall: 0.9584 - f1score: 0.9639\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _precision, _recall, _f1score = loaded_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade1b47",
   "metadata": {
    "id": "dade1b47"
   },
   "outputs": [],
   "source": [
    "def phishing_predict(new_sentence):\n",
    "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "  new_sentence = mecab.morphs(new_sentence)\n",
    "  new_sentence = [word for word in new_sentence if not word in stopwords]\n",
    "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
    "  pad_new = pad_sequences(encoded, maxlen = max_len)\n",
    "\n",
    "  score = float(loaded_model.predict(pad_new))\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 피싱입니다.\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 정상입니다.\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11054ba4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11054ba4",
    "outputId": "6b0ec84d-e337-44d1-887d-1933a3e9d41c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 496ms/step\n",
      "99.98% 확률로 피싱입니다.\n"
     ]
    }
   ],
   "source": [
    "phishing_predict('안녕하세요 은행인데요 대출 관련 전화입니다 통화 가능하신가요 네')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf37",
   "language": "python",
   "name": "tf37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
